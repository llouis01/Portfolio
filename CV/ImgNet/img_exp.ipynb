{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Drive Mount #"
      ],
      "metadata": {
        "id": "42agdHzUGlhk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EjPYD8y5DI-H",
        "outputId": "69c743fd-6224-4180-a936-4960c317ed37"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oIJfJqKO0p0z"
      },
      "source": [
        "# ** Utils.py Import ** #"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\" Utils for importing images and data \"\"\"\n",
        "\n",
        "## library imports ##\n",
        "import os\n",
        "import cv2\n",
        "import time\n",
        "import random\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from concurrent.futures import ThreadPoolExecutor\n",
        "\n",
        "\n",
        "## func to import test and val images\n",
        "def import_others(img_dir, img_num=int):\n",
        "    \"\"\" Import images from the specified directory \"\"\"\n",
        "    start = time.time()\n",
        "    processed_images = []\n",
        "    img_paths = []\n",
        "\n",
        "    def process_image_batches(img_paths, processed_images, img_num):\n",
        "        \"\"\" Import images from the specified directory \"\"\"\n",
        "\n",
        "        # read in image, resize, grayscale, and normalize\n",
        "        for i in range(0, img_num):\n",
        "            img_path = cv2.imread(img_paths[i])\n",
        "            img = cv2.resize(img_path, (224, 224))\n",
        "            img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "            img = np.expand_dims(img, axis = 2)\n",
        "            img = img / 255.0\n",
        "            processed_images.append(img)\n",
        "            completed_percentage = (i / img_num) * 100\n",
        "            if completed_percentage in [25, 50, 75, 100]:\n",
        "                print(f\"Images processed: {i} ({round(completed_percentage)}%)\")\n",
        "\n",
        "    # collect image paths\n",
        "    for root, dirs, files in os.walk(img_dir):\n",
        "            for file in files:\n",
        "                if file.endswith(\".JPEG\"):\n",
        "                     img_paths.append(os.path.join(root, file))\n",
        "\n",
        "    # shuffle images to get random images from random folders and process while generating labels\n",
        "    random.shuffle(img_paths)\n",
        "    process_image_batches(img_paths, processed_images, img_num)\n",
        "\n",
        "    # return run stats and data\n",
        "    end = time.time()\n",
        "    print(f\"Function processed {img_dir} in {round(end - start)} seconds.\\n\")\n",
        "    return processed_images\n",
        "\n",
        "\n",
        "## func to view training images with their assigned labels\n",
        "def view_train_images(x, y, n = 5):\n",
        "    \"\"\" view train data \"\"\"\n",
        "    for img in range(0, 5):\n",
        "        plt.imshow(x[img], cmap=\"gray\")\n",
        "        plt.show()\n",
        "        print(y[img])\n",
        "\n",
        "\n",
        "def plot_training_results(history):\n",
        "     \"\"\" Plot Accuracy Results \"\"\"\n",
        "     plt.figure(figsize=(12, 4))\n",
        "     plt.subplot(1, 2, 1)\n",
        "     plt.plot(history.history['accuracy'])\n",
        "     plt.plot(history.history['val_accuracy'])\n",
        "     plt.title('Model Accuracy')\n",
        "     plt.xlabel('Epoch')\n",
        "     plt.ylabel('Accuracy')\n",
        "     plt.legend(['Train', 'Val'], loc='best')\n",
        "     plt.show()\n",
        "\n",
        "     \"\"\" Plot Loss Results \"\"\"\n",
        "     plt.subplot(1, 2, 2)\n",
        "     plt.plot(history.history['loss'])\n",
        "     plt.plot(history.history['val_loss'])\n",
        "     plt.title('Model Loss')\n",
        "     plt.xlabel('Epoch')\n",
        "     plt.ylabel('Loss')\n",
        "     plt.legend(['Train', 'Val'], loc='best')\n",
        "     plt.show()\n",
        "\n",
        "\n",
        "def fast_import2(img_dir, img_num=int):\n",
        "    \"\"\" Import and preprocess images concurrently from the specified directory \"\"\"\n",
        "    start = time.time()\n",
        "\n",
        "    # Helper function to process individual images\n",
        "    def process_image(img_path):\n",
        "        \"\"\" Read and preprocess a single image, returning the processed image and its label \"\"\"\n",
        "        img = cv2.imread(img_path)\n",
        "        img = cv2.resize(img, (128, 128), interpolation=cv2.INTER_CUBIC)\n",
        "        img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "        img = np.expand_dims(img, axis=2)\n",
        "        img = img / 255.0\n",
        "        label = img_path.split(os.path.sep)[-2]  # label is the parent folder of the image\n",
        "        return img, label\n",
        "\n",
        "    # Collect image paths\n",
        "    img_paths = [os.path.join(root, file)\n",
        "                 for root, dirs, files in os.walk(img_dir)\n",
        "                 for file in files if file.endswith(\".JPEG\")]\n",
        "\n",
        "    # Shuffle images to get random images from random folders\n",
        "    random.shuffle(img_paths)\n",
        "    img_num = min(img_num, len(img_paths))\n",
        "    img_paths = img_paths[:img_num]\n",
        "\n",
        "    processed_images = []\n",
        "    labels = []\n",
        "\n",
        "    # Use ThreadPoolExecutor to process images concurrently\n",
        "    with ThreadPoolExecutor(max_workers=8) as executor:  # You can adjust the number of threads here\n",
        "        results = executor.map(process_image, img_paths)\n",
        "\n",
        "    # Collect processed images and labels\n",
        "    for img, label in results:\n",
        "        processed_images.append(img)\n",
        "        labels.append(label)\n",
        "\n",
        "    # Output stats\n",
        "    end = time.time()\n",
        "    print(f\"Function processed {img_num} images in {round(end - start)} seconds.\\n\")\n",
        "\n",
        "    return processed_images, labels\n",
        "\n",
        "\n",
        "# func to get data for CV project\n",
        "def get_images(train_dir, val_dir, train_num = 0):\n",
        "    \"\"\" Get data for CV project \"\"\"\n",
        "    X_train, Y_train = fast_import2(train_dir, train_num)\n",
        "    X_val, Y_val = fast_import2(val_dir, int(.15 * train_num))\n",
        "    return X_train, Y_train, X_val, Y_val"
      ],
      "metadata": {
        "id": "z2no2jIyCGSO"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M7Up2Vhz_fBR"
      },
      "source": [
        "https://hub.docker.com/r/tensorflow/tensorflow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "f9bNrWRM0p02"
      },
      "outputs": [],
      "source": [
        "# Import libraries\n",
        "import os\n",
        "import cv2\n",
        "import time\n",
        "import random\n",
        "import gc as G\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from pathlib import Path\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import backend as K, mixed_precision\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.metrics import Precision, Recall\n",
        "from tensorflow.keras.optimizers import Adam, SGD\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau as RLOP\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, GlobalAveragePooling2D, BatchNormalization\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "bkC5sSUipX8L",
        "outputId": "a4b17789-e8f2-40cf-d57f-47b0bd9d058d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.18.0\n",
            "Num GPUs Available:  1\n",
            "Using device: /GPU:0\n"
          ]
        }
      ],
      "source": [
        "# # set up for GPU usage\n",
        "K.clear_session()\n",
        "print(tf.__version__)\n",
        "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n",
        "\n",
        "device = \"/GPU:0\" if tf.config.list_physical_devices('GPU') else \"/CPU:0\"\n",
        "print(f\"Using device: {device}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "yXx3t9tQpX8O",
        "outputId": "2a38285c-ba87-4128-e57b-351f9e46b9e2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enabled memory growth for: PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')\n",
            "Using device: /GPU:0\n",
            "Set TensorFlow to use max GPU memory.\n"
          ]
        }
      ],
      "source": [
        "# limit usage of GPU memory\n",
        "gpus = tf.config.list_physical_devices('GPU')\n",
        "if gpus:\n",
        "    try:\n",
        "        for gpu in gpus:\n",
        "            tf.config.experimental.set_memory_growth(gpu, True)  # Prevents TensorFlow from allocating all memory at once\n",
        "            print(f\"Enabled memory growth for: {gpu}\")\n",
        "\n",
        "        # Set GPU device\n",
        "        device = \"/GPU:0\"\n",
        "    except RuntimeError as e:\n",
        "        print(e)\n",
        "else:\n",
        "    device = \"/CPU:0\"\n",
        "    print(\"No GPU detected, using CPU.\")\n",
        "\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "# set gpu to use max memory\n",
        "if gpus:\n",
        "    try:\n",
        "        for gpu in gpus:\n",
        "            tf.config.set_logical_device_configuration(\n",
        "                gpu,\n",
        "                [tf.config.LogicalDeviceConfiguration(memory_limit=4000)]  # Set in MB (e.g., 10GB)\n",
        "            )\n",
        "        print(\"Set TensorFlow to use max GPU memory.\")\n",
        "    except RuntimeError as e:\n",
        "        print(e)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hlbcvDAA0p01"
      },
      "source": [
        "# 1) Data Import #"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "sgQo6Eih0p02"
      },
      "outputs": [],
      "source": [
        "# paths for data\n",
        "train_dir = \"/content/drive/MyDrive/Colab Notebooks/data/small_train\"\n",
        "# val_dir = \"C:/Users/RoiMinuit/Desktop/data/ILSVRC/Data/CLS-LOC/val\"\n",
        "# test_dir = \"C:/Users/RoiMinuit/Desktop/data/ILSVRC/Data/CLS-LOC/test\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "UGptdkCf0p02",
        "outputId": "fa334ebd-aaef-480a-d073-25ddb6f862c9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Function processed 5000 images in 361 seconds.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# import images\n",
        "train_images, train_labels = fast_import2(train_dir, 5000)\n",
        "# test_images = import_others(test_dir, 750)\n",
        "# val_images = import_others(val_dir, 750)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QXO3VM3A0p03"
      },
      "outputs": [],
      "source": [
        "# prepare training data\n",
        "# tf.compat.v1.disable_eager_execution()\n",
        "X_train = np.array(train_images)\n",
        "X_train = np.repeat(X_train, 3, -1)\n",
        "\n",
        "Y_train = [str(s) for s in train_labels]\n",
        "label_encoder = LabelEncoder()\n",
        "Y_train = label_encoder.fit_transform(Y_train)\n",
        "Y_hot = to_categorical(Y_train)\n",
        "\n",
        "# X_train = tf.convert_to_tensor(X_train, dtype=tf.float32)\n",
        "# Y_hot = tf.convert_to_tensor(Y_hot, dtype=tf.float32)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "id97YGzB0p03"
      },
      "source": [
        "# 4) Model Definition #"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OdEf8QBo0p03"
      },
      "source": [
        "### b) Base CNN Model ###"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "veuSeMm80p03"
      },
      "outputs": [],
      "source": [
        "# 2) GPU-build and compile the convolutional neural network (CNN) model - ONLY ONCE\n",
        "K.clear_session()\n",
        "policy = mixed_precision.Policy('mixed_float16')\n",
        "mixed_precision.set_global_policy(policy)\n",
        "# Allow memory growth on the GPU\n",
        "# physical_devices = tf.config.list_physical_devices('GPU')\n",
        "# for device in physical_devices:\n",
        "#     tf.config.experimental.set_memory_growth(device, True)\n",
        "# strategy = tf.distribute.MirroredStrategy()\n",
        "# with strategy.scope():\n",
        "with tf.device('/GPU:0'):\n",
        "    CNN2 = keras.Sequential([\n",
        "                    # first convolutional layer\n",
        "                    Conv2D(32, (3, 3), activation='relu', input_shape=(64, 64, 3)),\n",
        "                    BatchNormalization(),\n",
        "                    MaxPooling2D((2, 2)),\n",
        "                    # second convolutional layer with 64 neurons and w/out shape\n",
        "                    Conv2D(64, (3, 3), activation='relu'),\n",
        "                    BatchNormalization(),\n",
        "                    MaxPooling2D((2, 2)),\n",
        "                    # third convolutional layer with 64 neurons and w/out shape\n",
        "                    Conv2D(128, (3, 3), activation='relu'),\n",
        "                    BatchNormalization(),\n",
        "                    MaxPooling2D((2, 2)),\n",
        "                    # # Flatten out the layers\n",
        "                    # Flatten(),\n",
        "                    # Dense layer with 64 neurons and relu activation\n",
        "                    GlobalAveragePooling2D(),\n",
        "                    BatchNormalization(),\n",
        "                    # Dropout layer to prevent overfitting by dropping 50% of neurons\n",
        "                    Dropout(0.4),\n",
        "                    # Output layer with 1000 classes and softmax activation\n",
        "                    Dense(1000, activation='softmax')\n",
        "            ])\n",
        "\n",
        "    # compile model with adam, categorical crossentropy, accuracy, precision, and recall\n",
        "    early_stop = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
        "    CNN2.compile(optimizer=keras.optimizers.Adam(learning_rate=0.0001),\n",
        "                    loss='categorical_crossentropy',\n",
        "                    metrics=['accuracy', Precision(), Recall()])\n",
        "\n",
        "# train the model\n",
        "K.clear_session()\n",
        "hist_2 = CNN2.fit(\n",
        "    X_train, Y_hot,\n",
        "    batch_size=8,\n",
        "    epochs=50,\n",
        "    validation_split=0.2,\n",
        "    callbacks=[early_stop]\n",
        ")\n",
        "\n",
        "# plot training results\n",
        "plot_training_results(hist_2)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "### c) Test Base Model ###"
      ],
      "metadata": {
        "id": "2G_XdlLQHoCi"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def build_model(lr=0.05):\n",
        "  CNN2 = keras.Sequential([\n",
        "                    # first convolutional layer\n",
        "                    Conv2D(32, (3, 3), activation='relu', input_shape=(128, 128, 3)),\n",
        "                    BatchNormalization(),\n",
        "                    MaxPooling2D((2, 2)),\n",
        "                    # second convolutional layer with 64 neurons and w/out shape\n",
        "                    Conv2D(64, (3, 3), activation='relu'),\n",
        "                    BatchNormalization(),\n",
        "                    MaxPooling2D((2, 2)),\n",
        "                    # third convolutional layer with 64 neurons and w/out shape\n",
        "                    Conv2D(64, (3, 3), activation='relu'),\n",
        "                    BatchNormalization(),\n",
        "                    MaxPooling2D((2, 2)),\n",
        "                    # # Flatten out the layers\n",
        "                    # Flatten(),\n",
        "                    # Dense layer with 64 neurons and relu activation\n",
        "                    GlobalAveragePooling2D(),\n",
        "                    BatchNormalization(),\n",
        "                    # Dropout layer to prevent overfitting by dropping 50% of neurons\n",
        "                    Dropout(0.4),\n",
        "                    # Output layer with 1000 classes and softmax activation\n",
        "                    Dense(len(Y_hot[0]), activation='softmax')\n",
        "            ])\n",
        "  CNN2.compile(optimizer=keras.optimizers.Adam(learning_rate=lr),\n",
        "                    loss='categorical_crossentropy',\n",
        "                    metrics=['accuracy', Precision(), Recall()])\n",
        "  return CNN2\n",
        "\n",
        "def train_model(model, batch=8, epx=10):\n",
        "  hist = model.fit(\n",
        "          X_train, Y_hot,\n",
        "          batch_size=batch,\n",
        "          epochs=epx,\n",
        "          validation_split=0.2\n",
        "        )\n",
        "  return hist\n",
        "\n",
        "def test_all(lr, model, batch, epx):\n",
        "  return plot_training_results(train_model(build_model(lr), batch=batch, epx=epx))"
      ],
      "metadata": {
        "id": "3nOt_WhoHs_t"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_all(0.03, train_model(build_model(), ))"
      ],
      "metadata": {
        "id": "1jZdmHAHH2nB"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.21"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}