{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Drive Mount #"
      ],
      "metadata": {
        "id": "42agdHzUGlhk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EjPYD8y5DI-H",
        "outputId": "69c743fd-6224-4180-a936-4960c317ed37"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oIJfJqKO0p0z"
      },
      "source": [
        "# ** Utils.py Import ** #"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\" Utils for importing images and data \"\"\"\n",
        "\n",
        "## library imports ##\n",
        "import os\n",
        "import cv2\n",
        "import time\n",
        "import random\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from concurrent.futures import ThreadPoolExecutor\n",
        "\n",
        "\n",
        "## func to import test and val images\n",
        "def import_others(img_dir, img_num=int):\n",
        "    \"\"\" Import images from the specified directory \"\"\"\n",
        "    start = time.time()\n",
        "    processed_images = []\n",
        "    img_paths = []\n",
        "\n",
        "    def process_image_batches(img_paths, processed_images, img_num):\n",
        "        \"\"\" Import images from the specified directory \"\"\"\n",
        "\n",
        "        # read in image, resize, grayscale, and normalize\n",
        "        for i in range(0, img_num):\n",
        "            img_path = cv2.imread(img_paths[i])\n",
        "            img = cv2.resize(img_path, (224, 224))\n",
        "            img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "            img = np.expand_dims(img, axis = 2)\n",
        "            img = img / 255.0\n",
        "            processed_images.append(img)\n",
        "            completed_percentage = (i / img_num) * 100\n",
        "            if completed_percentage in [25, 50, 75, 100]:\n",
        "                print(f\"Images processed: {i} ({round(completed_percentage)}%)\")\n",
        "\n",
        "    # collect image paths\n",
        "    for root, dirs, files in os.walk(img_dir):\n",
        "            for file in files:\n",
        "                if file.endswith(\".JPEG\"):\n",
        "                     img_paths.append(os.path.join(root, file))\n",
        "\n",
        "    # shuffle images to get random images from random folders and process while generating labels\n",
        "    random.shuffle(img_paths)\n",
        "    process_image_batches(img_paths, processed_images, img_num)\n",
        "\n",
        "    # return run stats and data\n",
        "    end = time.time()\n",
        "    print(f\"Function processed {img_dir} in {round(end - start)} seconds.\\n\")\n",
        "    return processed_images\n",
        "\n",
        "\n",
        "## func to view training images with their assigned labels\n",
        "def view_train_images(x, y, n = 5):\n",
        "    \"\"\" view train data \"\"\"\n",
        "    for img in range(0, 5):\n",
        "        plt.imshow(x[img], cmap=\"gray\")\n",
        "        plt.show()\n",
        "        print(y[img])\n",
        "\n",
        "\n",
        "def plot_training_results(history):\n",
        "     \"\"\" Plot Accuracy Results \"\"\"\n",
        "     plt.figure(figsize=(12, 4))\n",
        "     plt.subplot(1, 2, 1)\n",
        "     plt.plot(history.history['accuracy'])\n",
        "     plt.plot(history.history['val_accuracy'])\n",
        "     plt.title('Model Accuracy')\n",
        "     plt.xlabel('Epoch')\n",
        "     plt.ylabel('Accuracy')\n",
        "     plt.legend(['Train', 'Val'], loc='best')\n",
        "     plt.show()\n",
        "\n",
        "     \"\"\" Plot Loss Results \"\"\"\n",
        "     plt.subplot(1, 2, 2)\n",
        "     plt.plot(history.history['loss'])\n",
        "     plt.plot(history.history['val_loss'])\n",
        "     plt.title('Model Loss')\n",
        "     plt.xlabel('Epoch')\n",
        "     plt.ylabel('Loss')\n",
        "     plt.legend(['Train', 'Val'], loc='best')\n",
        "     plt.show()\n",
        "\n",
        "\n",
        "def fast_import2(img_dir, img_num=int):\n",
        "    \"\"\" Import and preprocess images concurrently from the specified directory \"\"\"\n",
        "    start = time.time()\n",
        "\n",
        "    # Helper function to process individual images\n",
        "    def process_image(img_path):\n",
        "        \"\"\" Read and preprocess a single image, returning the processed image and its label \"\"\"\n",
        "        img = cv2.imread(img_path)\n",
        "        img = cv2.resize(img, (128, 128), interpolation=cv2.INTER_CUBIC)\n",
        "        img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "        img = np.expand_dims(img, axis=2)\n",
        "        img = img / 255.0\n",
        "        label = img_path.split(os.path.sep)[-2]  # label is the parent folder of the image\n",
        "        return img, label\n",
        "\n",
        "    # Collect image paths\n",
        "    img_paths = [os.path.join(root, file)\n",
        "                 for root, dirs, files in os.walk(img_dir)\n",
        "                 for file in files if file.endswith(\".JPEG\")]\n",
        "\n",
        "    # Shuffle images to get random images from random folders\n",
        "    random.shuffle(img_paths)\n",
        "    img_num = min(img_num, len(img_paths))\n",
        "    img_paths = img_paths[:img_num]\n",
        "\n",
        "    # Use ThreadPoolExecutor to process images concurrently and yield results\n",
        "    with ThreadPoolExecutor(max_workers=8) as executor:  # You can adjust the number of threads here\n",
        "        results = executor.map(process_image, img_paths)\n",
        "        for img, label in results:\n",
        "            yield img, label\n",
        "\n",
        "\n",
        "    # Output stats (This part might need adjustment if you want to print stats after yielding all images)\n",
        "    end = time.time()\n",
        "    print(f\"Function finished processing images from {img_dir} in {round(end - start)} seconds.\\n\")\n",
        "\n",
        "\n",
        "# func to get data for CV project\n",
        "def get_images(train_dir, val_dir, train_num = 0):\n",
        "    \"\"\" Get data for CV project \"\"\"\n",
        "    X_train, Y_train = fast_import2(train_dir, train_num)\n",
        "    X_val, Y_val = fast_import2(val_dir, int(.15 * train_num))\n",
        "    return X_train, Y_train, X_val, Y_val"
      ],
      "metadata": {
        "id": "z2no2jIyCGSO"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M7Up2Vhz_fBR"
      },
      "source": [
        "https://hub.docker.com/r/tensorflow/tensorflow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "f9bNrWRM0p02"
      },
      "outputs": [],
      "source": [
        "# Import libraries\n",
        "import os\n",
        "import cv2\n",
        "import time\n",
        "import random\n",
        "import gc as G\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from pathlib import Path\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import backend as K, mixed_precision\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.metrics import Precision, Recall\n",
        "from tensorflow.keras.optimizers import Adam, SGD\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau as RLOP\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, GlobalAveragePooling2D, BatchNormalization\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "bkC5sSUipX8L",
        "outputId": "2a842d15-1b75-4c0e-c09c-a8cb55b4a862",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.18.0\n",
            "Num GPUs Available:  1\n",
            "Using device: /GPU:0\n"
          ]
        }
      ],
      "source": [
        "# # set up for GPU usage\n",
        "K.clear_session()\n",
        "print(tf.__version__)\n",
        "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n",
        "\n",
        "device = \"/GPU:0\" if tf.config.list_physical_devices('GPU') else \"/CPU:0\"\n",
        "print(f\"Using device: {device}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "yXx3t9tQpX8O",
        "outputId": "0df7eb8f-394e-4511-e91c-1102f4b88b18",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 373
        }
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "Cannot set memory growth on device when virtual devices configured",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-19-3009330266.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mgpu\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mgpus\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m             \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_memory_growth\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgpu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Prevents TensorFlow from allocating all memory at once\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Enabled memory growth for: {gpu}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/framework/config.py\u001b[0m in \u001b[0;36mset_memory_growth\u001b[0;34m(device, enable)\u001b[0m\n\u001b[1;32m    752\u001b[0m     \u001b[0mRuntimeError\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mRuntime\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0malready\u001b[0m \u001b[0minitialized\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    753\u001b[0m   \"\"\"\n\u001b[0;32m--> 754\u001b[0;31m   \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_memory_growth\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    755\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    756\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/context.py\u001b[0m in \u001b[0;36mset_memory_growth\u001b[0;34m(self, dev, enable)\u001b[0m\n\u001b[1;32m   1978\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1979\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mdev\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_virtual_device_map\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1980\u001b[0;31m       raise ValueError(\n\u001b[0m\u001b[1;32m   1981\u001b[0m           \u001b[0;34m\"Cannot set memory growth on device when virtual devices configured\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1982\u001b[0m       )\n",
            "\u001b[0;31mValueError\u001b[0m: Cannot set memory growth on device when virtual devices configured"
          ]
        }
      ],
      "source": [
        "# limit usage of GPU memory\n",
        "gpus = tf.config.list_physical_devices('GPU')\n",
        "if gpus:\n",
        "    try:\n",
        "        for gpu in gpus:\n",
        "            tf.config.experimental.set_memory_growth(gpu, True)  # Prevents TensorFlow from allocating all memory at once\n",
        "            print(f\"Enabled memory growth for: {gpu}\")\n",
        "\n",
        "        # Set GPU device\n",
        "        device = \"/GPU:0\"\n",
        "    except RuntimeError as e:\n",
        "        print(e)\n",
        "else:\n",
        "    device = \"/CPU:0\"\n",
        "    print(\"No GPU detected, using CPU.\")\n",
        "\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "# set gpu to use max memory\n",
        "if gpus:\n",
        "    try:\n",
        "        for gpu in gpus:\n",
        "            tf.config.set_logical_device_configuration(\n",
        "                gpu,\n",
        "                [tf.config.LogicalDeviceConfiguration(memory_limit=4000)]  # Set in MB (e.g., 10GB)\n",
        "            )\n",
        "        print(\"Set TensorFlow to use max GPU memory.\")\n",
        "    except RuntimeError as e:\n",
        "        print(e)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hlbcvDAA0p01"
      },
      "source": [
        "# 1) Data Import #"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "sgQo6Eih0p02"
      },
      "outputs": [],
      "source": [
        "# paths for data\n",
        "train_dir = \"/content/drive/MyDrive/Colab Notebooks/data/small_train\"\n",
        "# val_dir = \"C:/Users/RoiMinuit/Desktop/data/ILSVRC/Data/CLS-LOC/val\"\n",
        "# test_dir = \"C:/Users/RoiMinuit/Desktop/data/ILSVRC/Data/CLS-LOC/test\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "UGptdkCf0p02"
      },
      "outputs": [],
      "source": [
        "# import images\n",
        "train_generator = fast_import2(train_dir, 5000)\n",
        "# test_images = import_others(test_dir, 750)\n",
        "# val_images = import_others(val_dir, 750)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "QXO3VM3A0p03",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "df861590-c761-402a-b235-dad77981aed4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Function finished processing images from /content/drive/MyDrive/Colab Notebooks/data/small_train in 133 seconds.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "with tf.device(device):\n",
        "  # prepare training data\n",
        "  # tf.compat.v1.disable_eager_execution()\n",
        "  X_train = []\n",
        "  Y_train = []\n",
        "  for img, label in train_generator:\n",
        "      X_train.append(img)\n",
        "      Y_train.append(label)\n",
        "\n",
        "  X_train = np.array(X_train)\n",
        "  X_train = np.repeat(X_train, 3, -1)\n",
        "\n",
        "  Y_train = [str(s) for s in Y_train]\n",
        "  label_encoder = LabelEncoder()\n",
        "  Y_train = label_encoder.fit_transform(Y_train)\n",
        "  Y_hot = to_categorical(Y_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "id97YGzB0p03"
      },
      "source": [
        "# 4) Model Definition #"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### c) Test Base Model ###"
      ],
      "metadata": {
        "id": "Y0Z63esaJc6t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def build_model(lr=0.05):\n",
        "  CNN2 = keras.Sequential([\n",
        "                    # first convolutional layer\n",
        "                    Conv2D(32, (3, 3), activation='relu', input_shape=(128, 128, 3)),\n",
        "                    BatchNormalization(),\n",
        "                    MaxPooling2D((2, 2)),\n",
        "                    # second convolutional layer with 64 neurons and w/out shape\n",
        "                    Conv2D(64, (3, 3), activation='relu'),\n",
        "                    BatchNormalization(),\n",
        "                    MaxPooling2D((2, 2)),\n",
        "                    # third convolutional layer with 64 neurons and w/out shape\n",
        "                    Conv2D(64, (3, 3), activation='relu'),\n",
        "                    BatchNormalization(),\n",
        "                    MaxPooling2D((2, 2)),\n",
        "                    # # Flatten out the layers\n",
        "                    # Flatten(),\n",
        "                    # Dense layer with 64 neurons and relu activation\n",
        "                    GlobalAveragePooling2D(),\n",
        "                    BatchNormalization(),\n",
        "                    # Dropout layer to prevent overfitting by dropping 50% of neurons\n",
        "                    Dropout(0.4),\n",
        "                    # Output layer with 1000 classes and softmax activation\n",
        "                    Dense(len(Y_hot[0]), activation='softmax')\n",
        "            ])\n",
        "  CNN2.compile(optimizer=keras.optimizers.Adam(learning_rate=lr),\n",
        "                    loss='categorical_crossentropy',\n",
        "                    metrics=['accuracy', Precision(), Recall()])\n",
        "  return CNN2\n",
        "\n",
        "def train_model(model, batch=0, epx=0):\n",
        "  hist = model.fit(\n",
        "          X_train, Y_hot,\n",
        "          batch_size=batch,\n",
        "          epochs=epx,\n",
        "          validation_split=0.2\n",
        "        )\n",
        "  return hist\n",
        "\n",
        "def test_all(lr, model, batch, epx):\n",
        "  return plot_training_results(train_model(build_model(lr), batch=batch, epx=epx))"
      ],
      "metadata": {
        "id": "3nOt_WhoHs_t"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_all(0.02, train_model(build_model()), 32, 250)\n",
        "K.clear_session()\n",
        "G.collect()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1jZdmHAHH2nB",
        "outputId": "c9f09b3d-95ae-4282-c66f-d1897ac7dbf4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/250\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 42ms/step - accuracy: 0.1141 - loss: 3.0850 - precision_1: 0.1046 - recall_1: 0.0063 - val_accuracy: 0.0740 - val_loss: 3.0132 - val_precision_1: 0.1972 - val_recall_1: 0.0140\n",
            "Epoch 2/250\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 20ms/step - accuracy: 0.1558 - loss: 2.6216 - precision_1: 0.1683 - recall_1: 0.0015 - val_accuracy: 0.0500 - val_loss: 3.6089 - val_precision_1: 0.0560 - val_recall_1: 0.0470\n",
            "Epoch 3/250\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 19ms/step - accuracy: 0.1614 - loss: 2.6177 - precision_1: 0.3260 - recall_1: 0.0031 - val_accuracy: 0.0660 - val_loss: 3.0838 - val_precision_1: 0.1786 - val_recall_1: 0.0100\n",
            "Epoch 4/250\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 20ms/step - accuracy: 0.1825 - loss: 2.5684 - precision_1: 0.5914 - recall_1: 0.0060 - val_accuracy: 0.0750 - val_loss: 4.6547 - val_precision_1: 0.1489 - val_recall_1: 0.0210\n",
            "Epoch 5/250\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 22ms/step - accuracy: 0.2247 - loss: 2.4714 - precision_1: 0.4342 - recall_1: 0.0134 - val_accuracy: 0.1270 - val_loss: 3.7631 - val_precision_1: 0.1483 - val_recall_1: 0.0430\n",
            "Epoch 6/250\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 20ms/step - accuracy: 0.2315 - loss: 2.4233 - precision_1: 0.4394 - recall_1: 0.0164 - val_accuracy: 0.1640 - val_loss: 2.5958 - val_precision_1: 0.5714 - val_recall_1: 0.0080\n",
            "Epoch 7/250\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 19ms/step - accuracy: 0.2267 - loss: 2.4364 - precision_1: 0.4590 - recall_1: 0.0177 - val_accuracy: 0.0840 - val_loss: 12.6861 - val_precision_1: 0.0815 - val_recall_1: 0.0790\n",
            "Epoch 8/250\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 22ms/step - accuracy: 0.2324 - loss: 2.4130 - precision_1: 0.4713 - recall_1: 0.0286 - val_accuracy: 0.1290 - val_loss: 3.2622 - val_precision_1: 0.2772 - val_recall_1: 0.0510\n",
            "Epoch 9/250\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 20ms/step - accuracy: 0.2455 - loss: 2.3584 - precision_1: 0.5278 - recall_1: 0.0283 - val_accuracy: 0.1860 - val_loss: 2.9171 - val_precision_1: 0.6383 - val_recall_1: 0.0300\n",
            "Epoch 10/250\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 19ms/step - accuracy: 0.2924 - loss: 2.2842 - precision_1: 0.4815 - recall_1: 0.0362 - val_accuracy: 0.1530 - val_loss: 2.8490 - val_precision_1: 0.3059 - val_recall_1: 0.0260\n",
            "Epoch 11/250\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 19ms/step - accuracy: 0.2843 - loss: 2.2644 - precision_1: 0.5709 - recall_1: 0.0546 - val_accuracy: 0.1100 - val_loss: 3.4663 - val_precision_1: 0.2014 - val_recall_1: 0.0280\n",
            "Epoch 12/250\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 22ms/step - accuracy: 0.2816 - loss: 2.2450 - precision_1: 0.5408 - recall_1: 0.0587 - val_accuracy: 0.1590 - val_loss: 3.0848 - val_precision_1: 0.3039 - val_recall_1: 0.0620\n",
            "Epoch 13/250\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 21ms/step - accuracy: 0.2868 - loss: 2.2550 - precision_1: 0.5717 - recall_1: 0.0556 - val_accuracy: 0.2910 - val_loss: 2.2615 - val_precision_1: 0.7121 - val_recall_1: 0.0470\n",
            "Epoch 14/250\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 20ms/step - accuracy: 0.3195 - loss: 2.1923 - precision_1: 0.5792 - recall_1: 0.0692 - val_accuracy: 0.2050 - val_loss: 2.5316 - val_precision_1: 0.5000 - val_recall_1: 0.0190\n",
            "Epoch 15/250\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 20ms/step - accuracy: 0.2946 - loss: 2.2224 - precision_1: 0.5552 - recall_1: 0.0757 - val_accuracy: 0.1580 - val_loss: 4.1200 - val_precision_1: 0.1862 - val_recall_1: 0.0620\n",
            "Epoch 16/250\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 21ms/step - accuracy: 0.3610 - loss: 2.0697 - precision_1: 0.6125 - recall_1: 0.1053 - val_accuracy: 0.0670 - val_loss: 6.2096 - val_precision_1: 0.0869 - val_recall_1: 0.0570\n",
            "Epoch 17/250\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 20ms/step - accuracy: 0.3382 - loss: 2.0904 - precision_1: 0.5494 - recall_1: 0.1039 - val_accuracy: 0.2320 - val_loss: 2.7296 - val_precision_1: 0.4048 - val_recall_1: 0.1340\n",
            "Epoch 18/250\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 19ms/step - accuracy: 0.3456 - loss: 2.0847 - precision_1: 0.6072 - recall_1: 0.1114 - val_accuracy: 0.2540 - val_loss: 2.7699 - val_precision_1: 0.3124 - val_recall_1: 0.1640\n",
            "Epoch 19/250\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 20ms/step - accuracy: 0.3689 - loss: 1.9983 - precision_1: 0.6242 - recall_1: 0.1552 - val_accuracy: 0.3020 - val_loss: 2.2631 - val_precision_1: 0.5677 - val_recall_1: 0.1090\n",
            "Epoch 20/250\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 19ms/step - accuracy: 0.3647 - loss: 2.0083 - precision_1: 0.6075 - recall_1: 0.1339 - val_accuracy: 0.1900 - val_loss: 5.8401 - val_precision_1: 0.1974 - val_recall_1: 0.1070\n",
            "Epoch 21/250\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 20ms/step - accuracy: 0.3738 - loss: 1.9866 - precision_1: 0.6148 - recall_1: 0.1522 - val_accuracy: 0.3250 - val_loss: 2.2256 - val_precision_1: 0.4872 - val_recall_1: 0.1140\n",
            "Epoch 22/250\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 20ms/step - accuracy: 0.3867 - loss: 1.9355 - precision_1: 0.6418 - recall_1: 0.1665 - val_accuracy: 0.3370 - val_loss: 2.4129 - val_precision_1: 0.4499 - val_recall_1: 0.1660\n",
            "Epoch 23/250\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 20ms/step - accuracy: 0.3884 - loss: 1.9306 - precision_1: 0.6165 - recall_1: 0.1676 - val_accuracy: 0.1640 - val_loss: 3.3797 - val_precision_1: 0.2345 - val_recall_1: 0.1060\n",
            "Epoch 24/250\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 20ms/step - accuracy: 0.4028 - loss: 1.9050 - precision_1: 0.6652 - recall_1: 0.1778 - val_accuracy: 0.2870 - val_loss: 2.4306 - val_precision_1: 0.4241 - val_recall_1: 0.1620\n",
            "Epoch 25/250\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 20ms/step - accuracy: 0.4096 - loss: 1.8535 - precision_1: 0.6550 - recall_1: 0.1866 - val_accuracy: 0.2170 - val_loss: 4.0874 - val_precision_1: 0.2590 - val_recall_1: 0.1440\n",
            "Epoch 26/250\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 22ms/step - accuracy: 0.4031 - loss: 1.8697 - precision_1: 0.6731 - recall_1: 0.1968 - val_accuracy: 0.3050 - val_loss: 2.3090 - val_precision_1: 0.5227 - val_recall_1: 0.1150\n",
            "Epoch 27/250\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 19ms/step - accuracy: 0.4087 - loss: 1.8438 - precision_1: 0.6361 - recall_1: 0.1946 - val_accuracy: 0.2190 - val_loss: 3.2014 - val_precision_1: 0.2648 - val_recall_1: 0.1340\n",
            "Epoch 28/250\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 19ms/step - accuracy: 0.4287 - loss: 1.7791 - precision_1: 0.6417 - recall_1: 0.2055 - val_accuracy: 0.0710 - val_loss: 12.1028 - val_precision_1: 0.0712 - val_recall_1: 0.0710\n",
            "Epoch 29/250\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 20ms/step - accuracy: 0.4424 - loss: 1.7343 - precision_1: 0.6537 - recall_1: 0.2296 - val_accuracy: 0.2050 - val_loss: 3.1860 - val_precision_1: 0.2456 - val_recall_1: 0.1410\n",
            "Epoch 30/250\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 20ms/step - accuracy: 0.4362 - loss: 1.7645 - precision_1: 0.6826 - recall_1: 0.2251 - val_accuracy: 0.2580 - val_loss: 2.9837 - val_precision_1: 0.3382 - val_recall_1: 0.1620\n",
            "Epoch 31/250\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 21ms/step - accuracy: 0.4448 - loss: 1.7321 - precision_1: 0.6494 - recall_1: 0.2484 - val_accuracy: 0.2320 - val_loss: 2.8081 - val_precision_1: 0.3136 - val_recall_1: 0.1540\n",
            "Epoch 32/250\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 20ms/step - accuracy: 0.4639 - loss: 1.6843 - precision_1: 0.6571 - recall_1: 0.2659 - val_accuracy: 0.1920 - val_loss: 3.7822 - val_precision_1: 0.2182 - val_recall_1: 0.1560\n",
            "Epoch 33/250\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 20ms/step - accuracy: 0.4621 - loss: 1.6716 - precision_1: 0.6563 - recall_1: 0.2514 - val_accuracy: 0.2670 - val_loss: 3.9327 - val_precision_1: 0.3323 - val_recall_1: 0.2250\n",
            "Epoch 34/250\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 21ms/step - accuracy: 0.4649 - loss: 1.6602 - precision_1: 0.6739 - recall_1: 0.2728 - val_accuracy: 0.2690 - val_loss: 3.4413 - val_precision_1: 0.3488 - val_recall_1: 0.2030\n",
            "Epoch 35/250\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 19ms/step - accuracy: 0.4723 - loss: 1.6329 - precision_1: 0.6848 - recall_1: 0.2921 - val_accuracy: 0.3360 - val_loss: 2.1826 - val_precision_1: 0.5246 - val_recall_1: 0.1920\n",
            "Epoch 36/250\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 20ms/step - accuracy: 0.5054 - loss: 1.5700 - precision_1: 0.6970 - recall_1: 0.3003 - val_accuracy: 0.2630 - val_loss: 2.9566 - val_precision_1: 0.3540 - val_recall_1: 0.1880\n",
            "Epoch 37/250\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 19ms/step - accuracy: 0.4955 - loss: 1.5823 - precision_1: 0.6973 - recall_1: 0.3079 - val_accuracy: 0.1360 - val_loss: 6.6084 - val_precision_1: 0.1414 - val_recall_1: 0.1210\n",
            "Epoch 38/250\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 21ms/step - accuracy: 0.5107 - loss: 1.5463 - precision_1: 0.6886 - recall_1: 0.3199 - val_accuracy: 0.1820 - val_loss: 5.4850 - val_precision_1: 0.1866 - val_recall_1: 0.1530\n",
            "Epoch 39/250\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 20ms/step - accuracy: 0.4898 - loss: 1.5551 - precision_1: 0.6913 - recall_1: 0.3261 - val_accuracy: 0.2290 - val_loss: 3.7052 - val_precision_1: 0.2647 - val_recall_1: 0.1930\n",
            "Epoch 40/250\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 20ms/step - accuracy: 0.5121 - loss: 1.5089 - precision_1: 0.6827 - recall_1: 0.3353 - val_accuracy: 0.2330 - val_loss: 3.1154 - val_precision_1: 0.2717 - val_recall_1: 0.1630\n",
            "Epoch 41/250\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 19ms/step - accuracy: 0.5220 - loss: 1.4968 - precision_1: 0.6837 - recall_1: 0.3476 - val_accuracy: 0.1120 - val_loss: 10.6951 - val_precision_1: 0.1126 - val_recall_1: 0.1110\n",
            "Epoch 42/250\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 21ms/step - accuracy: 0.5392 - loss: 1.4243 - precision_1: 0.7049 - recall_1: 0.3761 - val_accuracy: 0.1770 - val_loss: 6.0616 - val_precision_1: 0.1845 - val_recall_1: 0.1520\n",
            "Epoch 43/250\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 21ms/step - accuracy: 0.5536 - loss: 1.4088 - precision_1: 0.7335 - recall_1: 0.3946 - val_accuracy: 0.1470 - val_loss: 6.5701 - val_precision_1: 0.1445 - val_recall_1: 0.1380\n",
            "Epoch 44/250\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 20ms/step - accuracy: 0.5467 - loss: 1.4105 - precision_1: 0.7057 - recall_1: 0.3924 - val_accuracy: 0.2570 - val_loss: 3.0250 - val_precision_1: 0.3096 - val_recall_1: 0.2220\n",
            "Epoch 45/250\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 20ms/step - accuracy: 0.5637 - loss: 1.3481 - precision_1: 0.7230 - recall_1: 0.4130 - val_accuracy: 0.1270 - val_loss: 4.7232 - val_precision_1: 0.1258 - val_recall_1: 0.1120\n",
            "Epoch 46/250\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 20ms/step - accuracy: 0.5732 - loss: 1.3303 - precision_1: 0.7359 - recall_1: 0.4206 - val_accuracy: 0.3530 - val_loss: 3.2494 - val_precision_1: 0.3919 - val_recall_1: 0.3010\n",
            "Epoch 47/250\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 22ms/step - accuracy: 0.5717 - loss: 1.3258 - precision_1: 0.7027 - recall_1: 0.4264 - val_accuracy: 0.1920 - val_loss: 4.4653 - val_precision_1: 0.1911 - val_recall_1: 0.1680\n",
            "Epoch 48/250\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 19ms/step - accuracy: 0.5844 - loss: 1.3029 - precision_1: 0.7370 - recall_1: 0.4282 - val_accuracy: 0.2370 - val_loss: 3.9898 - val_precision_1: 0.2976 - val_recall_1: 0.1970\n",
            "Epoch 49/250\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 19ms/step - accuracy: 0.5735 - loss: 1.3007 - precision_1: 0.7311 - recall_1: 0.4234 - val_accuracy: 0.1310 - val_loss: 9.3413 - val_precision_1: 0.1344 - val_recall_1: 0.1210\n",
            "Epoch 50/250\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 20ms/step - accuracy: 0.6051 - loss: 1.2242 - precision_1: 0.7444 - recall_1: 0.4752 - val_accuracy: 0.1560 - val_loss: 6.2860 - val_precision_1: 0.1652 - val_recall_1: 0.1490\n",
            "Epoch 51/250\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 20ms/step - accuracy: 0.5867 - loss: 1.2704 - precision_1: 0.7425 - recall_1: 0.4448 - val_accuracy: 0.3040 - val_loss: 3.1322 - val_precision_1: 0.3700 - val_recall_1: 0.2520\n",
            "Epoch 52/250\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 22ms/step - accuracy: 0.5975 - loss: 1.2510 - precision_1: 0.7392 - recall_1: 0.4560 - val_accuracy: 0.1690 - val_loss: 6.5184 - val_precision_1: 0.1772 - val_recall_1: 0.1570\n",
            "Epoch 53/250\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 20ms/step - accuracy: 0.6113 - loss: 1.2215 - precision_1: 0.7296 - recall_1: 0.4837 - val_accuracy: 0.0740 - val_loss: 13.6195 - val_precision_1: 0.0741 - val_recall_1: 0.0740\n",
            "Epoch 54/250\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 20ms/step - accuracy: 0.6024 - loss: 1.2260 - precision_1: 0.7324 - recall_1: 0.4735 - val_accuracy: 0.2530 - val_loss: 4.9081 - val_precision_1: 0.2744 - val_recall_1: 0.2390\n",
            "Epoch 55/250\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 21ms/step - accuracy: 0.6051 - loss: 1.2131 - precision_1: 0.7288 - recall_1: 0.4908 - val_accuracy: 0.2060 - val_loss: 6.5428 - val_precision_1: 0.2348 - val_recall_1: 0.1890\n",
            "Epoch 56/250\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 20ms/step - accuracy: 0.5993 - loss: 1.2368 - precision_1: 0.7183 - recall_1: 0.4785 - val_accuracy: 0.0800 - val_loss: 12.1583 - val_precision_1: 0.0807 - val_recall_1: 0.0800\n",
            "Epoch 57/250\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 20ms/step - accuracy: 0.6339 - loss: 1.1289 - precision_1: 0.7510 - recall_1: 0.5168 - val_accuracy: 0.1190 - val_loss: 7.8311 - val_precision_1: 0.1192 - val_recall_1: 0.1070\n",
            "Epoch 58/250\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 19ms/step - accuracy: 0.6524 - loss: 1.0747 - precision_1: 0.7641 - recall_1: 0.5349 - val_accuracy: 0.1740 - val_loss: 10.1835 - val_precision_1: 0.1820 - val_recall_1: 0.1660\n",
            "Epoch 59/250\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 21ms/step - accuracy: 0.6449 - loss: 1.0813 - precision_1: 0.7519 - recall_1: 0.5318 - val_accuracy: 0.1490 - val_loss: 8.6466 - val_precision_1: 0.1617 - val_recall_1: 0.1360\n",
            "Epoch 60/250\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 20ms/step - accuracy: 0.6348 - loss: 1.0756 - precision_1: 0.7373 - recall_1: 0.5197 - val_accuracy: 0.1100 - val_loss: 8.3995 - val_precision_1: 0.1132 - val_recall_1: 0.1080\n",
            "Epoch 61/250\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 20ms/step - accuracy: 0.6625 - loss: 1.0088 - precision_1: 0.7759 - recall_1: 0.5485 - val_accuracy: 0.1250 - val_loss: 7.1346 - val_precision_1: 0.1264 - val_recall_1: 0.1200\n",
            "Epoch 62/250\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 19ms/step - accuracy: 0.6697 - loss: 0.9989 - precision_1: 0.7670 - recall_1: 0.5657 - val_accuracy: 0.2270 - val_loss: 4.4822 - val_precision_1: 0.2377 - val_recall_1: 0.2080\n",
            "Epoch 63/250\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 20ms/step - accuracy: 0.6522 - loss: 1.0404 - precision_1: 0.7590 - recall_1: 0.5547 - val_accuracy: 0.1790 - val_loss: 4.9996 - val_precision_1: 0.1917 - val_recall_1: 0.1620\n",
            "Epoch 64/250\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 20ms/step - accuracy: 0.6658 - loss: 1.0138 - precision_1: 0.7838 - recall_1: 0.5664 - val_accuracy: 0.1490 - val_loss: 7.1241 - val_precision_1: 0.1591 - val_recall_1: 0.1370\n",
            "Epoch 65/250\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 20ms/step - accuracy: 0.6704 - loss: 0.9840 - precision_1: 0.7802 - recall_1: 0.5796 - val_accuracy: 0.2400 - val_loss: 5.1510 - val_precision_1: 0.2652 - val_recall_1: 0.2140\n",
            "Epoch 66/250\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 20ms/step - accuracy: 0.6954 - loss: 0.9648 - precision_1: 0.7799 - recall_1: 0.5879 - val_accuracy: 0.2310 - val_loss: 6.0533 - val_precision_1: 0.2417 - val_recall_1: 0.2120\n",
            "Epoch 67/250\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 21ms/step - accuracy: 0.6878 - loss: 0.9418 - precision_1: 0.7798 - recall_1: 0.5915 - val_accuracy: 0.1340 - val_loss: 12.9586 - val_precision_1: 0.1375 - val_recall_1: 0.1200\n",
            "Epoch 68/250\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 20ms/step - accuracy: 0.7124 - loss: 0.8960 - precision_1: 0.7997 - recall_1: 0.6228 - val_accuracy: 0.2620 - val_loss: 4.6102 - val_precision_1: 0.2876 - val_recall_1: 0.2370\n",
            "Epoch 69/250\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 20ms/step - accuracy: 0.6703 - loss: 0.9486 - precision_1: 0.7705 - recall_1: 0.5936 - val_accuracy: 0.2010 - val_loss: 7.3167 - val_precision_1: 0.2004 - val_recall_1: 0.1920\n",
            "Epoch 70/250\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 19ms/step - accuracy: 0.6850 - loss: 0.9448 - precision_1: 0.7725 - recall_1: 0.5972 - val_accuracy: 0.2940 - val_loss: 4.3697 - val_precision_1: 0.3333 - val_recall_1: 0.2580\n",
            "Epoch 71/250\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 20ms/step - accuracy: 0.6854 - loss: 0.9087 - precision_1: 0.7748 - recall_1: 0.6168 - val_accuracy: 0.1980 - val_loss: 8.8455 - val_precision_1: 0.2056 - val_recall_1: 0.1850\n",
            "Epoch 72/250\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 20ms/step - accuracy: 0.7251 - loss: 0.8371 - precision_1: 0.8126 - recall_1: 0.6445 - val_accuracy: 0.0460 - val_loss: 17.0217 - val_precision_1: 0.0461 - val_recall_1: 0.0460\n",
            "Epoch 73/250\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 19ms/step - accuracy: 0.7172 - loss: 0.8298 - precision_1: 0.7929 - recall_1: 0.6423 - val_accuracy: 0.0500 - val_loss: 23.0087 - val_precision_1: 0.0500 - val_recall_1: 0.0500\n",
            "Epoch 74/250\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 20ms/step - accuracy: 0.7185 - loss: 0.8448 - precision_1: 0.8016 - recall_1: 0.6384 - val_accuracy: 0.0950 - val_loss: 15.5027 - val_precision_1: 0.0960 - val_recall_1: 0.0950\n",
            "Epoch 75/250\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 20ms/step - accuracy: 0.7168 - loss: 0.8616 - precision_1: 0.7905 - recall_1: 0.6369 - val_accuracy: 0.1540 - val_loss: 5.9759 - val_precision_1: 0.1572 - val_recall_1: 0.1380\n",
            "Epoch 76/250\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 20ms/step - accuracy: 0.7137 - loss: 0.8627 - precision_1: 0.7876 - recall_1: 0.6459 - val_accuracy: 0.1110 - val_loss: 14.2353 - val_precision_1: 0.1120 - val_recall_1: 0.1110\n",
            "Epoch 77/250\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 19ms/step - accuracy: 0.7236 - loss: 0.8310 - precision_1: 0.7964 - recall_1: 0.6494 - val_accuracy: 0.2060 - val_loss: 6.2275 - val_precision_1: 0.2141 - val_recall_1: 0.1820\n",
            "Epoch 78/250\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 19ms/step - accuracy: 0.7161 - loss: 0.8249 - precision_1: 0.8016 - recall_1: 0.6510 - val_accuracy: 0.2540 - val_loss: 5.8867 - val_precision_1: 0.2773 - val_recall_1: 0.2390\n",
            "Epoch 79/250\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 21ms/step - accuracy: 0.7271 - loss: 0.8216 - precision_1: 0.8028 - recall_1: 0.6544 - val_accuracy: 0.0930 - val_loss: 11.6001 - val_precision_1: 0.0908 - val_recall_1: 0.0880\n",
            "Epoch 80/250\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 20ms/step - accuracy: 0.7415 - loss: 0.7983 - precision_1: 0.8115 - recall_1: 0.6724 - val_accuracy: 0.2220 - val_loss: 7.1600 - val_precision_1: 0.2397 - val_recall_1: 0.2090\n",
            "Epoch 81/250\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 20ms/step - accuracy: 0.7149 - loss: 0.8455 - precision_1: 0.7937 - recall_1: 0.6432 - val_accuracy: 0.1720 - val_loss: 9.9198 - val_precision_1: 0.1889 - val_recall_1: 0.1660\n",
            "Epoch 82/250\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 21ms/step - accuracy: 0.7415 - loss: 0.7799 - precision_1: 0.8120 - recall_1: 0.6747 - val_accuracy: 0.1820 - val_loss: 7.2029 - val_precision_1: 0.1874 - val_recall_1: 0.1670\n",
            "Epoch 83/250\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 20ms/step - accuracy: 0.7418 - loss: 0.7776 - precision_1: 0.8111 - recall_1: 0.6831 - val_accuracy: 0.2200 - val_loss: 5.4445 - val_precision_1: 0.2428 - val_recall_1: 0.2020\n",
            "Epoch 84/250\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 19ms/step - accuracy: 0.7408 - loss: 0.7797 - precision_1: 0.8120 - recall_1: 0.6824 - val_accuracy: 0.1320 - val_loss: 11.7154 - val_precision_1: 0.1307 - val_recall_1: 0.1270\n",
            "Epoch 85/250\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 19ms/step - accuracy: 0.7477 - loss: 0.7285 - precision_1: 0.8020 - recall_1: 0.6897 - val_accuracy: 0.1060 - val_loss: 14.1221 - val_precision_1: 0.1051 - val_recall_1: 0.1040\n",
            "Epoch 86/250\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 21ms/step - accuracy: 0.7564 - loss: 0.7176 - precision_1: 0.8189 - recall_1: 0.6921 - val_accuracy: 0.2390 - val_loss: 9.8268 - val_precision_1: 0.2487 - val_recall_1: 0.2320\n",
            "Epoch 87/250\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 20ms/step - accuracy: 0.7576 - loss: 0.7152 - precision_1: 0.8244 - recall_1: 0.7125 - val_accuracy: 0.2540 - val_loss: 4.3452 - val_precision_1: 0.2750 - val_recall_1: 0.2230\n",
            "Epoch 88/250\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 20ms/step - accuracy: 0.7543 - loss: 0.7389 - precision_1: 0.8100 - recall_1: 0.6849 - val_accuracy: 0.2520 - val_loss: 6.5682 - val_precision_1: 0.2660 - val_recall_1: 0.2450\n",
            "Epoch 89/250\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 25ms/step - accuracy: 0.7721 - loss: 0.7226 - precision_1: 0.8195 - recall_1: 0.7167 - val_accuracy: 0.2220 - val_loss: 9.0371 - val_precision_1: 0.2248 - val_recall_1: 0.2140\n",
            "Epoch 90/250\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 20ms/step - accuracy: 0.7703 - loss: 0.7031 - precision_1: 0.8194 - recall_1: 0.7241 - val_accuracy: 0.1980 - val_loss: 6.2605 - val_precision_1: 0.2078 - val_recall_1: 0.1910\n",
            "Epoch 91/250\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 20ms/step - accuracy: 0.7470 - loss: 0.7448 - precision_1: 0.8116 - recall_1: 0.7079 - val_accuracy: 0.1370 - val_loss: 8.9355 - val_precision_1: 0.1375 - val_recall_1: 0.1330\n",
            "Epoch 92/250\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 19ms/step - accuracy: 0.7839 - loss: 0.6408 - precision_1: 0.8455 - recall_1: 0.7306 - val_accuracy: 0.1190 - val_loss: 12.2405 - val_precision_1: 0.1213 - val_recall_1: 0.1190\n",
            "Epoch 93/250\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 21ms/step - accuracy: 0.7583 - loss: 0.7179 - precision_1: 0.8139 - recall_1: 0.7160 - val_accuracy: 0.2380 - val_loss: 6.0284 - val_precision_1: 0.2422 - val_recall_1: 0.2020\n",
            "Epoch 94/250\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 22ms/step - accuracy: 0.7799 - loss: 0.6728 - precision_1: 0.8295 - recall_1: 0.7253 - val_accuracy: 0.2540 - val_loss: 4.8766 - val_precision_1: 0.2722 - val_recall_1: 0.2360\n",
            "Epoch 95/250\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 19ms/step - accuracy: 0.7773 - loss: 0.6894 - precision_1: 0.8266 - recall_1: 0.7259 - val_accuracy: 0.1340 - val_loss: 12.5417 - val_precision_1: 0.1359 - val_recall_1: 0.1340\n",
            "Epoch 96/250\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 19ms/step - accuracy: 0.7348 - loss: 0.7659 - precision_1: 0.7980 - recall_1: 0.6818 - val_accuracy: 0.1640 - val_loss: 7.6933 - val_precision_1: 0.1767 - val_recall_1: 0.1520\n",
            "Epoch 97/250\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 19ms/step - accuracy: 0.7881 - loss: 0.6518 - precision_1: 0.8442 - recall_1: 0.7316 - val_accuracy: 0.2400 - val_loss: 6.6553 - val_precision_1: 0.2522 - val_recall_1: 0.2340\n",
            "Epoch 98/250\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 20ms/step - accuracy: 0.7693 - loss: 0.6816 - precision_1: 0.8260 - recall_1: 0.7239 - val_accuracy: 0.1780 - val_loss: 7.6395 - val_precision_1: 0.1748 - val_recall_1: 0.1690\n",
            "Epoch 99/250\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 22ms/step - accuracy: 0.7725 - loss: 0.6767 - precision_1: 0.8193 - recall_1: 0.7234 - val_accuracy: 0.2390 - val_loss: 5.1438 - val_precision_1: 0.2565 - val_recall_1: 0.2180\n",
            "Epoch 100/250\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 20ms/step - accuracy: 0.7767 - loss: 0.6665 - precision_1: 0.8336 - recall_1: 0.7280 - val_accuracy: 0.1650 - val_loss: 11.5645 - val_precision_1: 0.1677 - val_recall_1: 0.1580\n",
            "Epoch 101/250\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 20ms/step - accuracy: 0.7817 - loss: 0.6070 - precision_1: 0.8442 - recall_1: 0.7436 - val_accuracy: 0.1020 - val_loss: 14.9348 - val_precision_1: 0.1000 - val_recall_1: 0.0960\n",
            "Epoch 102/250\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 19ms/step - accuracy: 0.7836 - loss: 0.6485 - precision_1: 0.8318 - recall_1: 0.7378 - val_accuracy: 0.2270 - val_loss: 7.7941 - val_precision_1: 0.2362 - val_recall_1: 0.2190\n",
            "Epoch 103/250\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 19ms/step - accuracy: 0.7824 - loss: 0.6540 - precision_1: 0.8338 - recall_1: 0.7413 - val_accuracy: 0.2270 - val_loss: 7.7014 - val_precision_1: 0.2417 - val_recall_1: 0.2100\n",
            "Epoch 104/250\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 22ms/step - accuracy: 0.7713 - loss: 0.6593 - precision_1: 0.8176 - recall_1: 0.7305 - val_accuracy: 0.1220 - val_loss: 12.9884 - val_precision_1: 0.1238 - val_recall_1: 0.1200\n",
            "Epoch 105/250\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 19ms/step - accuracy: 0.7906 - loss: 0.6302 - precision_1: 0.8376 - recall_1: 0.7496 - val_accuracy: 0.1340 - val_loss: 14.9718 - val_precision_1: 0.1333 - val_recall_1: 0.1300\n",
            "Epoch 106/250\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 20ms/step - accuracy: 0.7898 - loss: 0.6298 - precision_1: 0.8369 - recall_1: 0.7406 - val_accuracy: 0.2620 - val_loss: 11.5770 - val_precision_1: 0.2697 - val_recall_1: 0.2570\n",
            "Epoch 107/250\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 19ms/step - accuracy: 0.7940 - loss: 0.6084 - precision_1: 0.8375 - recall_1: 0.7522 - val_accuracy: 0.1390 - val_loss: 13.0670 - val_precision_1: 0.1415 - val_recall_1: 0.1340\n",
            "Epoch 108/250\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 20ms/step - accuracy: 0.7751 - loss: 0.6745 - precision_1: 0.8211 - recall_1: 0.7327 - val_accuracy: 0.1620 - val_loss: 9.1300 - val_precision_1: 0.1638 - val_recall_1: 0.1550\n",
            "Epoch 109/250\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 21ms/step - accuracy: 0.7978 - loss: 0.5870 - precision_1: 0.8415 - recall_1: 0.7585 - val_accuracy: 0.1750 - val_loss: 13.4135 - val_precision_1: 0.1777 - val_recall_1: 0.1740\n",
            "Epoch 110/250\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 20ms/step - accuracy: 0.8026 - loss: 0.5810 - precision_1: 0.8467 - recall_1: 0.7671 - val_accuracy: 0.0950 - val_loss: 14.5101 - val_precision_1: 0.0948 - val_recall_1: 0.0940\n",
            "Epoch 111/250\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 19ms/step - accuracy: 0.7976 - loss: 0.6110 - precision_1: 0.8380 - recall_1: 0.7592 - val_accuracy: 0.3000 - val_loss: 6.1777 - val_precision_1: 0.3147 - val_recall_1: 0.2820\n",
            "Epoch 112/250\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 21ms/step - accuracy: 0.7803 - loss: 0.6447 - precision_1: 0.8280 - recall_1: 0.7412 - val_accuracy: 0.2030 - val_loss: 6.4989 - val_precision_1: 0.2118 - val_recall_1: 0.1860\n",
            "Epoch 113/250\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 20ms/step - accuracy: 0.8166 - loss: 0.5290 - precision_1: 0.8533 - recall_1: 0.7792 - val_accuracy: 0.2360 - val_loss: 9.6703 - val_precision_1: 0.2444 - val_recall_1: 0.2300\n",
            "Epoch 114/250\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 20ms/step - accuracy: 0.8122 - loss: 0.5624 - precision_1: 0.8504 - recall_1: 0.7750 - val_accuracy: 0.1030 - val_loss: 15.5827 - val_precision_1: 0.1006 - val_recall_1: 0.0980\n",
            "Epoch 115/250\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 20ms/step - accuracy: 0.7999 - loss: 0.5819 - precision_1: 0.8515 - recall_1: 0.7627 - val_accuracy: 0.2700 - val_loss: 6.3342 - val_precision_1: 0.2803 - val_recall_1: 0.2570\n",
            "Epoch 116/250\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 20ms/step - accuracy: 0.8242 - loss: 0.5197 - precision_1: 0.8622 - recall_1: 0.7894 - val_accuracy: 0.1470 - val_loss: 11.1983 - val_precision_1: 0.1518 - val_recall_1: 0.1460\n",
            "Epoch 117/250\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 21ms/step - accuracy: 0.7990 - loss: 0.6242 - precision_1: 0.8394 - recall_1: 0.7597 - val_accuracy: 0.0940 - val_loss: 19.8843 - val_precision_1: 0.0942 - val_recall_1: 0.0940\n",
            "Epoch 118/250\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 20ms/step - accuracy: 0.7993 - loss: 0.5948 - precision_1: 0.8448 - recall_1: 0.7621 - val_accuracy: 0.2840 - val_loss: 6.9086 - val_precision_1: 0.3167 - val_recall_1: 0.2730\n",
            "Epoch 119/250\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 20ms/step - accuracy: 0.8338 - loss: 0.5022 - precision_1: 0.8675 - recall_1: 0.8005 - val_accuracy: 0.2040 - val_loss: 7.5163 - val_precision_1: 0.2154 - val_recall_1: 0.1960\n",
            "Epoch 120/250\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 19ms/step - accuracy: 0.8194 - loss: 0.5559 - precision_1: 0.8575 - recall_1: 0.7830 - val_accuracy: 0.1110 - val_loss: 15.7380 - val_precision_1: 0.1083 - val_recall_1: 0.1070\n",
            "Epoch 121/250\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 21ms/step - accuracy: 0.8033 - loss: 0.5517 - precision_1: 0.8481 - recall_1: 0.7769 - val_accuracy: 0.1280 - val_loss: 13.1494 - val_precision_1: 0.1284 - val_recall_1: 0.1270\n",
            "Epoch 122/250\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 21ms/step - accuracy: 0.8228 - loss: 0.5320 - precision_1: 0.8552 - recall_1: 0.7871 - val_accuracy: 0.2170 - val_loss: 10.2887 - val_precision_1: 0.2237 - val_recall_1: 0.2130\n",
            "Epoch 123/250\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 20ms/step - accuracy: 0.8019 - loss: 0.6058 - precision_1: 0.8447 - recall_1: 0.7721 - val_accuracy: 0.1130 - val_loss: 18.9267 - val_precision_1: 0.1144 - val_recall_1: 0.1130\n",
            "Epoch 124/250\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 20ms/step - accuracy: 0.8238 - loss: 0.5202 - precision_1: 0.8592 - recall_1: 0.7937 - val_accuracy: 0.1220 - val_loss: 15.4996 - val_precision_1: 0.1236 - val_recall_1: 0.1210\n",
            "Epoch 125/250\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 21ms/step - accuracy: 0.8083 - loss: 0.5581 - precision_1: 0.8419 - recall_1: 0.7769 - val_accuracy: 0.2280 - val_loss: 8.1836 - val_precision_1: 0.2348 - val_recall_1: 0.2130\n",
            "Epoch 126/250\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 20ms/step - accuracy: 0.8151 - loss: 0.5578 - precision_1: 0.8524 - recall_1: 0.7864 - val_accuracy: 0.1910 - val_loss: 9.1656 - val_precision_1: 0.1956 - val_recall_1: 0.1880\n",
            "Epoch 127/250\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 20ms/step - accuracy: 0.8403 - loss: 0.4780 - precision_1: 0.8730 - recall_1: 0.8041 - val_accuracy: 0.1800 - val_loss: 12.3137 - val_precision_1: 0.1874 - val_recall_1: 0.1760\n",
            "Epoch 128/250\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 22ms/step - accuracy: 0.8257 - loss: 0.4942 - precision_1: 0.8638 - recall_1: 0.8033 - val_accuracy: 0.2310 - val_loss: 5.8688 - val_precision_1: 0.2409 - val_recall_1: 0.2190\n",
            "Epoch 129/250\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 20ms/step - accuracy: 0.8211 - loss: 0.5070 - precision_1: 0.8549 - recall_1: 0.7944 - val_accuracy: 0.1670 - val_loss: 9.1876 - val_precision_1: 0.1726 - val_recall_1: 0.1600\n",
            "Epoch 130/250\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 20ms/step - accuracy: 0.8278 - loss: 0.5297 - precision_1: 0.8700 - recall_1: 0.7993 - val_accuracy: 0.2650 - val_loss: 5.6618 - val_precision_1: 0.2779 - val_recall_1: 0.2440\n",
            "Epoch 131/250\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 22ms/step - accuracy: 0.8104 - loss: 0.5901 - precision_1: 0.8450 - recall_1: 0.7841 - val_accuracy: 0.2140 - val_loss: 7.9294 - val_precision_1: 0.2259 - val_recall_1: 0.2110\n",
            "Epoch 132/250\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 20ms/step - accuracy: 0.8146 - loss: 0.5309 - precision_1: 0.8498 - recall_1: 0.7854 - val_accuracy: 0.1090 - val_loss: 19.8795 - val_precision_1: 0.1105 - val_recall_1: 0.1090\n",
            "Epoch 133/250\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 19ms/step - accuracy: 0.8336 - loss: 0.4929 - precision_1: 0.8741 - recall_1: 0.7999 - val_accuracy: 0.0930 - val_loss: 19.0156 - val_precision_1: 0.0926 - val_recall_1: 0.0920\n",
            "Epoch 134/250\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 20ms/step - accuracy: 0.8260 - loss: 0.5156 - precision_1: 0.8613 - recall_1: 0.7965 - val_accuracy: 0.2400 - val_loss: 9.7867 - val_precision_1: 0.2517 - val_recall_1: 0.2250\n",
            "Epoch 135/250\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 21ms/step - accuracy: 0.8256 - loss: 0.5443 - precision_1: 0.8567 - recall_1: 0.7949 - val_accuracy: 0.1410 - val_loss: 17.1510 - val_precision_1: 0.1436 - val_recall_1: 0.1390\n",
            "Epoch 136/250\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 20ms/step - accuracy: 0.8489 - loss: 0.4477 - precision_1: 0.8798 - recall_1: 0.8240 - val_accuracy: 0.2130 - val_loss: 7.8906 - val_precision_1: 0.2231 - val_recall_1: 0.2030\n",
            "Epoch 137/250\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 19ms/step - accuracy: 0.8292 - loss: 0.5246 - precision_1: 0.8575 - recall_1: 0.7986 - val_accuracy: 0.1210 - val_loss: 15.9896 - val_precision_1: 0.1196 - val_recall_1: 0.1170\n",
            "Epoch 138/250\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 20ms/step - accuracy: 0.8482 - loss: 0.4741 - precision_1: 0.8787 - recall_1: 0.8208 - val_accuracy: 0.1860 - val_loss: 7.1271 - val_precision_1: 0.1974 - val_recall_1: 0.1790\n",
            "Epoch 139/250\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 21ms/step - accuracy: 0.8440 - loss: 0.4711 - precision_1: 0.8730 - recall_1: 0.8188 - val_accuracy: 0.1230 - val_loss: 8.5411 - val_precision_1: 0.1242 - val_recall_1: 0.1190\n",
            "Epoch 140/250\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 21ms/step - accuracy: 0.8267 - loss: 0.5431 - precision_1: 0.8536 - recall_1: 0.8007 - val_accuracy: 0.2300 - val_loss: 6.1968 - val_precision_1: 0.2450 - val_recall_1: 0.2220\n",
            "Epoch 141/250\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 20ms/step - accuracy: 0.8369 - loss: 0.4940 - precision_1: 0.8686 - recall_1: 0.8074 - val_accuracy: 0.1080 - val_loss: 14.3863 - val_precision_1: 0.1072 - val_recall_1: 0.1060\n",
            "Epoch 142/250\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 22ms/step - accuracy: 0.8362 - loss: 0.4978 - precision_1: 0.8566 - recall_1: 0.8040 - val_accuracy: 0.1680 - val_loss: 11.9431 - val_precision_1: 0.1705 - val_recall_1: 0.1640\n",
            "Epoch 143/250\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 21ms/step - accuracy: 0.8272 - loss: 0.5000 - precision_1: 0.8667 - recall_1: 0.8013 - val_accuracy: 0.1470 - val_loss: 10.5776 - val_precision_1: 0.1462 - val_recall_1: 0.1430\n",
            "Epoch 144/250\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 20ms/step - accuracy: 0.8325 - loss: 0.5010 - precision_1: 0.8644 - recall_1: 0.8080 - val_accuracy: 0.2400 - val_loss: 11.7900 - val_precision_1: 0.2620 - val_recall_1: 0.2340\n",
            "Epoch 145/250\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 19ms/step - accuracy: 0.8329 - loss: 0.5122 - precision_1: 0.8570 - recall_1: 0.8036 - val_accuracy: 0.1790 - val_loss: 12.1938 - val_precision_1: 0.1809 - val_recall_1: 0.1760\n",
            "Epoch 146/250\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 20ms/step - accuracy: 0.8370 - loss: 0.4874 - precision_1: 0.8703 - recall_1: 0.8107 - val_accuracy: 0.1030 - val_loss: 16.1493 - val_precision_1: 0.1053 - val_recall_1: 0.1010\n",
            "Epoch 147/250\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 21ms/step - accuracy: 0.8314 - loss: 0.4879 - precision_1: 0.8673 - recall_1: 0.8076 - val_accuracy: 0.1580 - val_loss: 13.8526 - val_precision_1: 0.1590 - val_recall_1: 0.1530\n",
            "Epoch 148/250\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 19ms/step - accuracy: 0.8491 - loss: 0.4462 - precision_1: 0.8762 - recall_1: 0.8289 - val_accuracy: 0.2350 - val_loss: 10.1437 - val_precision_1: 0.2484 - val_recall_1: 0.2260\n",
            "Epoch 149/250\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 19ms/step - accuracy: 0.8375 - loss: 0.4891 - precision_1: 0.8618 - recall_1: 0.8193 - val_accuracy: 0.0860 - val_loss: 23.4234 - val_precision_1: 0.0863 - val_recall_1: 0.0860\n",
            "Epoch 150/250\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 20ms/step - accuracy: 0.8284 - loss: 0.5055 - precision_1: 0.8630 - recall_1: 0.7998 - val_accuracy: 0.1340 - val_loss: 13.1974 - val_precision_1: 0.1346 - val_recall_1: 0.1310\n",
            "Epoch 151/250\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 20ms/step - accuracy: 0.8490 - loss: 0.4558 - precision_1: 0.8780 - recall_1: 0.8327 - val_accuracy: 0.1430 - val_loss: 14.9108 - val_precision_1: 0.1461 - val_recall_1: 0.1420\n",
            "Epoch 152/250\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 22ms/step - accuracy: 0.8546 - loss: 0.4603 - precision_1: 0.8735 - recall_1: 0.8278 - val_accuracy: 0.1100 - val_loss: 18.9495 - val_precision_1: 0.1116 - val_recall_1: 0.1100\n",
            "Epoch 153/250\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 20ms/step - accuracy: 0.8378 - loss: 0.4827 - precision_1: 0.8662 - recall_1: 0.8138 - val_accuracy: 0.1680 - val_loss: 14.1931 - val_precision_1: 0.1717 - val_recall_1: 0.1640\n",
            "Epoch 154/250\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 21ms/step - accuracy: 0.8217 - loss: 0.5332 - precision_1: 0.8545 - recall_1: 0.8000 - val_accuracy: 0.2860 - val_loss: 5.6465 - val_precision_1: 0.3003 - val_recall_1: 0.2730\n",
            "Epoch 155/250\n",
            "\u001b[1m107/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.8313 - loss: 0.4980 - precision_1: 0.8603 - recall_1: 0.8062"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.21"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}